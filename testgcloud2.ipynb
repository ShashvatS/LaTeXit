{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "from enum import Enum\n",
    "from PIL import Image, ImageDraw\n",
    "# import json, jsonpickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(\"./convert/7.012noteslindrew-0.png\", 'rb') as image_file:\n",
    "    image = types.Image(content = image_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashvat/anaconda3/lib/python3.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.document_text_detection(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reponse.txt\", \"w\") as f:\n",
    "    f.write(str(response.full_text_annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    WORD = 4\n",
    "    SYMBOL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, bounds, color, thick = False):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        if not thick:\n",
    "            draw.polygon([\n",
    "                bound.vertices[0].x, bound.vertices[0].y,\n",
    "                bound.vertices[1].x, bound.vertices[1].y,\n",
    "                bound.vertices[2].x, bound.vertices[2].y,\n",
    "                bound.vertices[3].x, bound.vertices[3].y], None, color)\n",
    "        else:\n",
    "            points = [(i.x, i.y) for i in bound.vertices]\n",
    "            points.append(points[0])\n",
    "            draw.line(points, fill=color, width=9)\n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_bounds(response, feature):\n",
    "    \"\"\"Returns document bounds given an image.\"\"\"\n",
    "\n",
    "    bounds = []\n",
    "    document = response.full_text_annotation\n",
    "\n",
    "    # Collect specified feature bounds by enumerating all document features\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        if (feature == FeatureType.SYMBOL):\n",
    "                            bounds.append(symbol.bounding_box)\n",
    "\n",
    "                    if (feature == FeatureType.WORD):\n",
    "                        bounds.append(word.bounding_box)\n",
    "\n",
    "                if (feature == FeatureType.PARA):\n",
    "                    bounds.append(paragraph.bounding_box)\n",
    "\n",
    "            if (feature == FeatureType.BLOCK):\n",
    "                bounds.append(block.bounding_box)\n",
    "\n",
    "        if (feature == FeatureType.PAGE):\n",
    "            bounds.append(block.bounding_box)\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_doc_text(reponse, filein, fileout):    \n",
    "    image = Image.open(filein)\n",
    "    bounds = get_document_bounds(response, FeatureType.PAGE)\n",
    "    draw_boxes(image, bounds, 'blue', True)\n",
    "    bounds = get_document_bounds(response, FeatureType.BLOCK)\n",
    "    draw_boxes(image, bounds, 'green', True)\n",
    "    bounds = get_document_bounds(response, FeatureType.PARA)\n",
    "    draw_boxes(image, bounds, 'red')\n",
    "    bounds = get_document_bounds(response, FeatureType.WORD)\n",
    "    draw_boxes(image, bounds, 'yellow')\n",
    "    \n",
    "    if fileout is not 0:\n",
    "        image.save(fileout)\n",
    "    else:\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(\"./convert/7.012noteslindrew-0.png\", 'rb') as image_file:\n",
    "    image = types.Image(content = image_file.read())\n",
    "response = client.document_text_detection(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(filein):\n",
    "    with io.open(filein, 'rb') as image_file:\n",
    "        image = types.Image(content = image_file.read())\n",
    "    response = client.document_text_detection(image=image)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_doc_text(response, \"./convert/7.012noteslindrew-0.png\", \"tmp0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = get_response(\"./convert/7.012noteslindrew-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_doc_text(response3, \"./convert/7.012noteslindrew-3.png\", \"tmp3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"response.txt\", 'w') as f:\n",
    "    f.write(str(response))\n",
    "with open(\"response_fta.txt\", 'w') as f:\n",
    "    f.write(str(response.full_text_annotation))\n",
    "# with open(\"response_fta.json\", 'w') as f:\n",
    "#     f.write(jsonpickle.decode(response.full_text_annotation))\n",
    "with open(\"response3.txt\", 'w') as f:\n",
    "    f.write(str(response3))\n",
    "with open(\"response3_fta.txt\", 'w') as f:\n",
    "    f.write(str(response3.full_text_annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "special = \"&%$#_{}~^\\\\\"\n",
    "special_map = {}\n",
    "for s in special:\n",
    "    special_map[s] = \"\\\\\" + s\n",
    "special_map[\"~\"] = \"\\\\textasciitilde\"\n",
    "special_map[\"^\"] = \"\\\\textasciicircum\"\n",
    "special_map[\"\\\\\"] = \"\\\\textbackslash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sym(s):\n",
    "    if s in special_map.keys():\n",
    "        return special_map[s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detected_break(text, detected_break, in_itemize = False):\n",
    "    break_text = \"\"\n",
    "    kind = detected_break.type\n",
    "    \n",
    "    if kind:\n",
    "        if kind == 1:\n",
    "            break_text = \" \"\n",
    "        elif kind == 2:\n",
    "            break_text = \"    \"\n",
    "        elif kind == 3:\n",
    "            if in_itemize:\n",
    "                break_text = \"\\n\"\n",
    "            else:\n",
    "                break_text = \"\\n\\\\\\\\\"\n",
    "#             break_text = \"$3\\n\"\n",
    "        elif kind == 5:\n",
    "            if in_itemize:\n",
    "                break_text = \"\\n\"\n",
    "            else:\n",
    "                break_text = \"\\n\\\\\\\\\"\n",
    "#             break_text = \"$5\\n\"\n",
    "#         elif kind == 2:\n",
    "#             break_text = \" \"\n",
    "        \n",
    "#         elif \n",
    "\n",
    "    if detected_break.is_prefix:\n",
    "        return break_text + text\n",
    "    else:\n",
    "        return text + break_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_block(block):\n",
    "    b = \"\"\n",
    "    \n",
    "    in_itemize = False\n",
    "    \n",
    "    for paragraph in block.paragraphs:\n",
    "        p = \"\"\n",
    "        for word in paragraph.words:\n",
    "            w = \"\"\n",
    "            for symbol in word.symbols:\n",
    "                detected_break = symbol.property.detected_break\n",
    "                text = parse_sym(symbol.text)\n",
    "                \n",
    "                if text in \"â€¢-\":\n",
    "                    if not in_itemize:\n",
    "                        text += \"\\\\begin{itemize}\"\n",
    "                        in_itemize = True                        \n",
    "                    if in_itemize:\n",
    "                        text += \"\\\\item \"            \n",
    "                w += parse_detected_break(text, detected_break, in_itemize)\n",
    "            \n",
    "            p += parse_detected_break(w, word.property.detected_break, in_itemize)\n",
    "            \n",
    "        if in_itemize:\n",
    "            p += \"\\\\end{itemize}\\n\"\n",
    "            in_itemize = False\n",
    "        \n",
    "        b += parse_detected_break(p, paragraph.property.detected_break, in_itemize)\n",
    "\n",
    "    return parse_detected_break(b, block.property.detected_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"take3.tex\", 'w') as f:\n",
    "    \n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            f.write(extract_block(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"take5.tex\", 'w') as f:\n",
    "    \n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            text = extract_block(block)\n",
    "        \n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

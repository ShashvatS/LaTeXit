{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "from tqdm import tqdm\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashvat/anaconda3/lib/python3.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(filein):\n",
    "    with io.open(filein, 'rb') as image_file:\n",
    "        image = types.Image(content = image_file.read())\n",
    "    response = client.document_text_detection(image=image)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "for i in range(10):\n",
    "    filein = \"./convert/7.012noteslindrew-{}.png\".format(i)\n",
    "    response_list.append(get_response(filein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special = \"&%$#_{}~^\\\\\"\n",
    "special_map = {}\n",
    "for s in special:\n",
    "    special_map[s] = \"\\\\\" + s\n",
    "special_map[\"~\"] = \"\\\\textasciitilde\"\n",
    "special_map[\"^\"] = \"\\\\textasciicircum\"\n",
    "special_map[\"\\\\\"] = \"\\\\textbackslash\"\n",
    "special_map[\"[\"] = \"{[}\"\n",
    "special_map[\"]\"] = \"{]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sym(s):\n",
    "    if s in special_map.keys():\n",
    "        return special_map[s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detected_break(text, detected_break, in_itemize = False):\n",
    "    break_text = \"\"\n",
    "    kind = detected_break.type\n",
    "    \n",
    "    if kind:\n",
    "        if kind == 1:\n",
    "            break_text = \" \"\n",
    "        elif kind == 2:\n",
    "            break_text = \"    \"\n",
    "        elif kind == 3:\n",
    "            if in_itemize:\n",
    "                break_text = \"\\n\"\n",
    "            else:\n",
    "                break_text = \"\\\\\\\\\\n\"\n",
    "#             break_text = \"$3\\n\"\n",
    "        elif kind == 5:\n",
    "            if in_itemize:\n",
    "                break_text = \"\\n\"\n",
    "            else:\n",
    "                break_text = \"\\\\\\\\\\n\"\n",
    "#             break_text = \"$5\\n\"\n",
    "#         elif kind == 2:\n",
    "#             break_text = \" \"\n",
    "        \n",
    "#         elif \n",
    "\n",
    "    if detected_break.is_prefix:\n",
    "        return break_text + text\n",
    "    else:\n",
    "        return text + break_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sym_width(block):\n",
    "    widths = []\n",
    "    for paragraph in block.paragraphs:\n",
    "        for word in paragraph.words:\n",
    "            for sym in word.symbols:\n",
    "                widths.append(sym.bounding_box.vertices[1].x - sym.bounding_box.vertices[0].x)\n",
    "    return statistics.median(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_block(block):\n",
    "    avg_width = avg_sym_width(block)\n",
    "    \n",
    "    b = \"\"\n",
    "    \n",
    "    in_itemize = False\n",
    "    itemize_levels = 0\n",
    "    last_itemize = None\n",
    "    \n",
    "    for paragraph in block.paragraphs:\n",
    "        p = \"\"\n",
    "        for word in paragraph.words:\n",
    "            w = \"\"\n",
    "            for symbol in word.symbols:\n",
    "                detected_break = symbol.property.detected_break\n",
    "                text = parse_sym(symbol.text)\n",
    "                \n",
    "                if text == \".\" and (p == \"1\" or p == \"|\"):\n",
    "                    p = \"\"\n",
    "                    text = \"•\"\n",
    "                elif len(p) >= 2 and p[-2:] == \"\\n1\":\n",
    "                    text = \"•\"\n",
    "                    p = p[:-1]\n",
    "                    \n",
    "                washere = False\n",
    "                if text in \"•-\" and (p == \"\" or p[-1] == '\\n'):\n",
    "                    washere = True\n",
    "                \n",
    "                    print(in_itemize, p)\n",
    "                    \n",
    "                    text = \"\"\n",
    "                    if not in_itemize:\n",
    "                        text += \"\\\\begin{itemize}\\n\"\n",
    "                        in_itemize = True\n",
    "                        itemize_levels += 1\n",
    "                    if in_itemize:\n",
    "                        text += \"\\\\item \"\n",
    "                        \n",
    "                    if last_itemize and itemize_levels <= 3:\n",
    "                        dist = symbol.bounding_box.vertices[0].x - last_itemize.bounding_box.vertices[0].x\n",
    "                        \n",
    "                        y1 = [last_itemize.bounding_box.vertices[0].y, last_itemize.bounding_box.vertices[2].y]\n",
    "                        y2 = [symbol.bounding_box.vertices[0].y, symbol.bounding_box.vertices[2].y]\n",
    "            \n",
    "                        inter = set(range(y1[0], y1[1])).intersection(set(range(y2[0], y2[1])))\n",
    "                        if dist >= 4 * avg_width:\n",
    "                            print(\"here\")\n",
    "                            text = \"\\\\begin{itemize}\\n\" + text\n",
    "                            itemize_levels += 1\n",
    "                            in_itemize = True\n",
    "                        elif dist <= -4 * avg_width and itemize_levels >= 2:\n",
    "                            print(\"die\")\n",
    "                            text = \"\\\\end{itemize}\\n\" + text\n",
    "                            itemize_levels -= 1\n",
    "                            in_itemize = (itemize_levels != 0)\n",
    "                \n",
    "                    last_itemize = symbol\n",
    "                w += parse_detected_break(text, detected_break, in_itemize)\n",
    "            \n",
    "            if \"survey\" in w:\n",
    "                print(\"survey\", in_itemize, p)\n",
    "                \n",
    "            if in_itemize and \"\\\\item\" not in w:\n",
    "                if p != \"\" and p[-1] == '\\n':\n",
    "                    for _ in range(itemize_levels):\n",
    "                         p += \"\\\\end{itemize}\\n\"\n",
    "                    itemize_levels = 0\n",
    "                    in_itemize = False\n",
    "                    last_itemize = None\n",
    "                \n",
    "            p += parse_detected_break(w, word.property.detected_break, in_itemize)\n",
    "        \n",
    "        b += parse_detected_break(p, paragraph.property.detected_break, in_itemize)\n",
    "        \n",
    "    if in_itemize:\n",
    "        for _ in range(itemize_levels):\n",
    "             b += \"\\\\end{itemize}\\n\"\n",
    "        \n",
    "        itemize_levels = 0\n",
    "        in_itemize = False\n",
    "        last_itemize = None\n",
    "        \n",
    "    text = parse_detected_break(b, block.property.detected_break)\n",
    "    text = text.replace(\"\\\\\\\\\\\\begin{itemize}\", \"\\\\begin{itemize}\")\n",
    "    text = text.replace(\"\\\\\\\\\\n\\\\begin{itemize}\", \"\\n\\\\begin{itemize}\")\n",
    "#     text = text.replace(\"\\\\\\\\\\\\begin{itemize}\")\n",
    "#     text = text.replace(\"\\\\end{itemize}\\n\\\\begin{itemize}\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Lecture I\\\\\n",
      "\n",
      "True Lecture I\\\\\n",
      "\\begin{itemize}\n",
      "\\item  professor has a math PhD???\n",
      "\n",
      "False Important stuff\\\\\n",
      "\n",
      "False \n",
      "True \\begin{itemize}\n",
      "\\item  Office hours, recitations start next week\n",
      "\n",
      "survey True \\begin{itemize}\n",
      "\\item  Office hours, recitations start next week\n",
      "\\item  Fill out the mock submission \n",
      "False \\begin{itemize}\n",
      "\\item  Office hours, recitations start next week\n",
      "\\item  Fill out the mock submission survey!\n",
      "\\end{itemize}\n",
      "\n",
      "False \\begin{itemize}\n",
      "\\item  Office hours, recitations start next week\n",
      "\\item  Fill out the mock submission survey!\n",
      "\\end{itemize}\n",
      "\\begin{itemize}\n",
      "\\item  MITX?\n",
      "\\end{itemize}\n",
      "\n",
      "False You Do need to show up.\n",
      "\\end{itemize}\n",
      "\n",
      "True You Do need to show up.\n",
      "\\end{itemize}\n",
      "\\begin{itemize}\n",
      "\\item  Problem sets cannot be late. Collaboration is fine, but not copying.\n",
      "\n",
      "True \n",
      "here\n",
      "True \\begin{itemize}\n",
      "\\item  Paper textbook (Life), series of videos (see MITX), online textbook (!)\n",
      "\n",
      "False What is this class?\\\\\n",
      "\n",
      "False What is this class?\\\\\n",
      "\\begin{itemize}\n",
      "\\item  Medicine rapidly developing in the present\n",
      "\\end{itemize}\n",
      "\n",
      "True What is this class?\\\\\n",
      "\\begin{itemize}\n",
      "\\item  Medicine rapidly developing in the present\n",
      "\\end{itemize}\n",
      "\\begin{itemize}\n",
      "\\item  Cancer therapy, etc.\n",
      "\n",
      "True What is this class?\\\\\n",
      "\\begin{itemize}\n",
      "\\item  Medicine rapidly developing in the present\n",
      "\\end{itemize}\n",
      "\\begin{itemize}\n",
      "\\item  Cancer therapy, etc.\n",
      "\\item  DNA fingerprinting - then privacy issues, ancestry etc.\n",
      "\n",
      "False organelles, molecules (big to small)\\\\\n",
      "We focus on the small things because they are common.\\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"dev2take2.tex\", 'w') as f:\n",
    "    fmt = open(\"format.tex\", \"r\").read()\n",
    "    \n",
    "    al = \"\"\n",
    "    for response in response_list[:1]:\n",
    "        for page in response.full_text_annotation.pages:\n",
    "            for block in page.blocks:\n",
    "#                 print(avg_sym_width(block))\n",
    "                text = extract_block(block)\n",
    "                al += text\n",
    "                \n",
    "    text = fmt + al + \"\\\\end{document}\"\n",
    "                \n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
